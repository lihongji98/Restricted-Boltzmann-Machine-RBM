{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5a8967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980d82b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, \n",
    "                 v_dim, h_dim, \n",
    "                 lr=5e-4, \n",
    "                 gibbs_num = 1, \n",
    "                 epochs = 50000, \n",
    "                 batch_size = 1, \n",
    "                 compute_detail = True,\n",
    "                 binary_kind = \"withoutzero\"):\n",
    "        self.v_dim = v_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.lr = lr\n",
    "        self.v_bias = np.random.normal(-0.1, 0.1, size = (1,self.v_dim))\n",
    "        self.h_bias = np.random.normal(-0.1, 0.1, size =(1,self.h_dim))\n",
    "        self.W = np.random.normal(size = (self.v_dim, self.h_dim))\n",
    "        self.gibbs_num = gibbs_num\n",
    "        self.v_w, self.v_v, self.v_h = 0, 0, 0\n",
    "        self.momentum = 0.9\n",
    "        self.epochs = epochs\n",
    "        self.compute_detail = compute_detail\n",
    "        self.batch_size = batch_size\n",
    "        self.binary_kind = binary_kind\n",
    "        self.allcases = self.get_all_cases(self.binary_kind, self.v_dim)\n",
    "\n",
    "    def sample_h(self, v_input):\n",
    "        if self.binary_kind == \"withoutzero\":\n",
    "            var = -(np.dot(v_input, self.W) + self.h_bias)\n",
    "            p_h_v = 1/(1 + np.exp(2*var))\n",
    "            state_h = self.state_sample(p_h_v)\n",
    "        elif self.binary_kind == \"withzero\":\n",
    "            p_h_v = 1/(1 + np.exp(-(np.dot(v_input, self.W) + self.h_bias)))\n",
    "            state_h = self.state_sample(p_h_v)\n",
    "        else:\n",
    "            print(\"enter 'withzero' or 'withoutzero'!\")\n",
    "            \n",
    "        return state_h, p_h_v\n",
    "    \n",
    "    def sample_v(self, h):\n",
    "        if self.binary_kind == \"withoutzero\":\n",
    "            var = -(np.dot(h, self.W.T) + self.v_bias)\n",
    "            p_v_h = 1/(1 + np.exp(2*var))\n",
    "            state_v = self.state_sample(p_v_h)\n",
    "        elif self.binary_kind == \"withzero\":\n",
    "            p_v_h = 1/(1 + np.exp(-(np.dot(h, self.W.T) + self.v_bias)))\n",
    "            state_v = self.state_sample(p_v_h)\n",
    "        else:\n",
    "            print(\"enter 'withzero' or 'withoutzero'!\")\n",
    "        \n",
    "        return state_v, p_v_h\n",
    "\n",
    "    def state_sample(self, p):\n",
    "        state = []\n",
    "        uni = np.random.uniform(0,1, size=p[0].shape[0])\n",
    "        for i in range(len(p)):\n",
    "            condition = np.less(p[i], uni)\n",
    "            if self.binary_kind == \"withoutzero\":\n",
    "                state_node = np.where(condition, -1, 1)\n",
    "            elif self.binary_kind == \"withzero\":\n",
    "                state_node = np.where(condition, 0, 1)\n",
    "            else:\n",
    "                print(\"enter 'withzero' or 'withoutzero'!\")\n",
    "            state.append(state_node)\n",
    "\n",
    "        return np.array(state).reshape(p.shape[0], p.shape[1])\n",
    "\n",
    "    \n",
    "    def gibbs_sampling(self, v):\n",
    "        i = 0 \n",
    "        k = self.gibbs_num\n",
    "        v_0 = v\n",
    "\n",
    "        _, p_h0_v = self.sample_h(v_0)\n",
    "\n",
    "        while i < k:\n",
    "            state_h, _ = self.sample_h(v)\n",
    "            state_v, _ = self.sample_v(state_h)\n",
    "            i += 1\n",
    "\n",
    "        else: \n",
    "            v_k = state_v\n",
    "\n",
    "            _, p_hk_v = self.sample_h(v_k)\n",
    "        \n",
    "        return v_0, v_k, p_h0_v, p_hk_v\n",
    "        \n",
    "\n",
    "    def gradient_compute(self, v_0, v_k, p_h0_v, p_hk_v):\n",
    "        dw = (np.dot(v_0.T, p_h0_v) - np.dot(v_k.T, p_hk_v)) / self.batch_size\n",
    "        dh_bias = (np.sum(p_h0_v - p_hk_v)) / self.batch_size\n",
    "        dv_bias = (np.sum(v_0 - v_k)) / self.batch_size\n",
    "        \n",
    "        \n",
    "        self.v_w = self.momentum * self.v_w + (1 - self.momentum) * dw\n",
    "        self.v_h = self.momentum * self.v_h + (1 - self.momentum) * dh_bias\n",
    "        self.v_v = self.momentum * self.v_v + (1 - self.momentum) * dv_bias \n",
    "\n",
    "        self.W += self.lr * self.v_w\n",
    "        self.v_bias += self.lr * self.v_v\n",
    "        self.h_bias += self.lr * self.v_h \n",
    "    \n",
    "    def get_all_cases(self, binary_kind, v_dim):\n",
    "        def all_cases(nums, v_dim):\n",
    "            res = []\n",
    "            backtracking(nums, v_dim, [], 0, res)\n",
    "            return res\n",
    "\n",
    "        def backtracking(nums, v_dim, path, pos, res):\n",
    "            if len(path) > v_dim:\n",
    "                return\n",
    "            if len(path) == v_dim:\n",
    "                res.append(list(path))\n",
    "            for i in range(len(nums)):\n",
    "                path.append(nums[i])\n",
    "                backtracking(nums, v_dim, path, i + 1, res)\n",
    "                path.pop()\n",
    "        if binary_kind == \"withzero\":\n",
    "            return np.array(all_cases([0, 1], self.v_dim))\n",
    "        \n",
    "        elif binary_kind == \"withoutzero\":\n",
    "            return np.array(all_cases([-1, 1], self.v_dim))\n",
    "        else:\n",
    "            print(\"enter 'withzero' or 'withoutzero'!\")\n",
    "        \n",
    "\n",
    "    def compute_px_with_Z(self, train_data, W, v_bias, h_bias): \n",
    "        probability = []\n",
    "        if self.binary_kind == \"withoutzero\":\n",
    "            for l in range(len(train_data)):\n",
    "                train_data_one_piece = train_data[l]\n",
    "                product_value = 1\n",
    "                exp_av = np.exp(np.dot(v_bias, train_data_one_piece))\n",
    "                for i in range(h_bias.shape[1]):\n",
    "                    product_value = product_value * (np.exp(np.dot(W.T[i], train_data_one_piece)+ h_bias.T[i]) +\n",
    "                                                     np.exp(-np.dot(W.T[i], train_data_one_piece)- h_bias.T[i]))\n",
    "                px_with_Z = exp_av * product_value\n",
    "                probability.append(px_with_Z[0])\n",
    "        \n",
    "        elif self.binary_kind == \"withzero\":\n",
    "            for l in range(len(train_data)):\n",
    "                train_data_one_piece = train_data[l]\n",
    "                product_value = 1\n",
    "                exp_av = np.exp(np.dot(v_bias, train_data_one_piece))\n",
    "                for i in range(h_bias.shape[1]):\n",
    "                    product_value = product_value * (np.exp(np.dot(W.T[i], train_data_one_piece) + h_bias.T[i]) + 1)\n",
    "                px_with_Z = exp_av * product_value\n",
    "                probability.append(px_with_Z[0])\n",
    "                \n",
    "        else:\n",
    "            print(\"enter 'withzero' or 'withoutzero'!\")\n",
    "            \n",
    "        return probability\n",
    "    \n",
    "    def compute_Z(self, v_dim, W, v_bias, h_bias):\n",
    "        Z = 0\n",
    "        if self.binary_kind == \"withoutzero\":\n",
    "            for l in range(len(self.allcases)):\n",
    "                train_data_one = self.allcases[l]\n",
    "                exp_av = np.exp(np.dot(v_bias, train_data_one))\n",
    "                product = 1\n",
    "                for j in range(h_bias.shape[1]):\n",
    "                    product = product * (np.exp(np.dot(train_data_one.T, W.T[j]) + h_bias.T[j]) +\n",
    "                                         np.exp(-np.dot(train_data_one.T, W.T[j]) - h_bias.T[j]))\n",
    "                total = exp_av * product\n",
    "\n",
    "                Z += total\n",
    "                \n",
    "        elif self.binary_kind == \"withzero\":\n",
    "            for l in range(len(self.allcases)):\n",
    "                train_data_one = self.allcases[l]\n",
    "                exp_av = np.exp(np.dot(v_bias, train_data_one))\n",
    "                product = 1\n",
    "                for j in range(h_bias.shape[1]):\n",
    "                    product = product * (np.exp(np.dot(train_data_one.T, W.T[j]) + h_bias.T[j]) + 1)\n",
    "                total = exp_av * product\n",
    "\n",
    "                Z += total\n",
    "        else:\n",
    "            print(\"enter 'withzero' or 'withoutzero'!\")\n",
    "            \n",
    "        return Z\n",
    "    \n",
    "    def train(self, train_data):\n",
    "        idx = [i for i in range(train_data.shape[0])]\n",
    "        start = [i for i in idx if i%self.batch_size == 0]\n",
    "        end = []\n",
    "        for start_idx in start:\n",
    "            end_idx = start_idx + self.batch_size\n",
    "            if end_idx < len(idx):\n",
    "                end.append(end_idx)\n",
    "            else:\n",
    "                end.append(len(idx))\n",
    "        data_len = len(start)\n",
    "        \n",
    "        #for epoch in tqdm(range(self.epochs)):\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            for index in range(data_len):\n",
    "                v0 = train_data[start[index]: end[index]]\n",
    "                vk = v0.copy()\n",
    "                _, p_h0_v = self.sample_h(v0)\n",
    "                v0, vk, p_h0_v, p_hk_v = self.gibbs_sampling(v0)\n",
    "                self.gradient_compute(v0, vk, p_h0_v, p_hk_v)\n",
    "            \n",
    "            lowest_KL = float(\"inf\")\n",
    "            lowest_KL_epoch = 0\n",
    "            \n",
    "            if self.compute_detail:\n",
    "                KL_list, log_LKH_list = [], []\n",
    "                logLKH, KL = 0, 0\n",
    "                Z = self.compute_Z(train_data.shape[1], self.W, self.v_bias, self.h_bias) \n",
    "                probability_list = self.compute_px_with_Z(train_data, self.W, self.v_bias, self.h_bias)\n",
    "\n",
    "                for i in range(len(probability_list)):\n",
    "                    px_with_Z = probability_list[i]\n",
    "                    N = len(probability_list)\n",
    "                    log_lkh = np.log(px_with_Z) - np.log(Z) \n",
    "                    logLKH += log_lkh\n",
    "\n",
    "                    kl = -np.log(N)/N - np.log(px_with_Z)/N + np.log(Z)/N\n",
    "                    KL += kl\n",
    "                KL /= N\n",
    "                logLKH /= N\n",
    "                KL_list.append(KL)\n",
    "                log_LKH_list.append(logLKH)\n",
    "\n",
    "                probability_list = [probability_list[i]/Z for i in range(len(probability_list))]\n",
    "                x = np.sum(probability_list)\n",
    "                \n",
    "                epoch_end_time = time.time()\n",
    "                \n",
    "                if KL[0] < lowest_KL:\n",
    "                    lowest_KL = KL[0]\n",
    "                    lowest_KL_epoch = epoch\n",
    "                    \n",
    "                if(epoch % 100 == 0):\n",
    "                    results = 'epoch:{} ==>  KL = {}, logLKH = {}, prob_sum = {:.4f}, time = {:.2f}s'.format(epoch, \n",
    "                                                                                                             KL, \n",
    "                                                                                                             logLKH, \n",
    "                                                                                                             x, \n",
    "                                                                                                             epoch_end_time-epoch_start_time)\n",
    "                    #f=open(\"log -1&1.txt\",\"a\")\n",
    "                    #f=open(\"50000epochs1.txt\",\"a\")\n",
    "                    #f.write(results + '\\n')\n",
    "                    #f.close()\n",
    "                    print(results)\n",
    "            \n",
    "            else:\n",
    "                #if (epoch % 100 == 0):\n",
    "                #    results = 'epoch:{}/ {} done...'.format(epoch, self.epochs)\n",
    "                #    print(results)\n",
    "                if epoch + 1 == self.epochs:\n",
    "                    logLKH, KL = 0, 0\n",
    "                    Z = self.compute_Z(train_data.shape[1], self.W, self.v_bias, self.h_bias) \n",
    "                    probability_list = self.compute_px_with_Z(train_data, self.W, self.v_bias, self.h_bias)\n",
    "\n",
    "                    for i in range(len(probability_list)):\n",
    "                        px_with_Z = probability_list[i]\n",
    "                        N = len(probability_list)\n",
    "                        log_lkh = np.log(px_with_Z) - np.log(Z) \n",
    "                        logLKH += log_lkh\n",
    "\n",
    "                        kl = -np.log(N)/N - np.log(px_with_Z)/N + np.log(Z)/N\n",
    "                        KL += kl\n",
    "                    KL /= N\n",
    "                    logLKH /= N\n",
    "                    results = 'KL = {}, logLKH = {}'.format(KL, logLKH)\n",
    "                    print(results)\n",
    "        record = \"The lowest KL is {} in epoch {}\".format(lowest_KL, lowest_KL_epoch)\n",
    "        #f.write(record + '\\n')\n",
    "        #f.write('\\n')\n",
    "        print(record)\n",
    "        #f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8951efef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.28741398]\n",
      "epoch:0 ==>  KL = [1.28741398], logLKH = [-20.66285311], prob_sum = 0.0000, time = 0.09s\n",
      "[1.28638687]\n",
      "[1.28533224]\n",
      "[1.28384973]\n",
      "[1.28198306]\n",
      "[1.27987466]\n",
      "[1.27756601]\n",
      "[1.2754328]\n",
      "[1.27321141]\n",
      "[1.27107112]\n",
      "[1.268774]\n",
      "[1.26637246]\n",
      "[1.26404104]\n",
      "[1.26147628]\n",
      "[1.25883623]\n",
      "[1.25630483]\n",
      "[1.25378448]\n",
      "[1.25136069]\n",
      "[1.24905524]\n",
      "[1.24659536]\n",
      "[1.24393777]\n",
      "[1.24110605]\n",
      "[1.238295]\n",
      "[1.23528484]\n",
      "[1.23230357]\n",
      "[1.2295218]\n",
      "[1.22681432]\n",
      "[1.22421074]\n",
      "[1.22171312]\n",
      "[1.21926645]\n",
      "[1.21679233]\n",
      "[1.21457251]\n",
      "[1.21227294]\n",
      "[1.21011406]\n",
      "[1.20799624]\n",
      "[1.20549642]\n",
      "[1.20277911]\n",
      "[1.20014161]\n",
      "[1.19767303]\n",
      "[1.19521417]\n",
      "[1.1927736]\n",
      "[1.19045369]\n",
      "[1.1880647]\n",
      "[1.18578406]\n",
      "[1.18357687]\n",
      "[1.1811563]\n",
      "[1.17879773]\n",
      "[1.17657343]\n",
      "[1.17436654]\n",
      "[1.17235842]\n",
      "[1.1705403]\n",
      "[1.16870721]\n",
      "[1.1669242]\n",
      "[1.16511786]\n",
      "[1.16338606]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/92/zgzs76j97j3f_tf8rngzx_580000gn/T/ipykernel_63228/2032166766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mrbm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrbm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mrbm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/92/zgzs76j97j3f_tf8rngzx_580000gn/T/ipykernel_63228/3411938062.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mKL_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_LKH_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mlogLKH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_Z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0mprobability_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_px_with_Z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/92/zgzs76j97j3f_tf8rngzx_580000gn/T/ipykernel_63228/3411938062.py\u001b[0m in \u001b[0;36mcompute_Z\u001b[0;34m(self, v_dim, W, v_bias, h_bias)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                     product = product * (np.exp(np.dot(train_data_one.T, W.T[j]) + h_bias.T[j]) +\n\u001b[0;32m--> 162\u001b[0;31m                                          np.exp(-np.dot(train_data_one.T, W.T[j]) - h_bias.T[j]))\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_av\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data1 = np.loadtxt(r'3x3pn.txt')\n",
    "train_data2 = np.loadtxt(r'3x3.txt')\n",
    "\n",
    "visible_node_num = train_data1.shape[1]\n",
    "hidden_node_num = 18\n",
    "lr = 1e-3\n",
    "#gibbs_num = 1\n",
    "rbm1 = RBM(visible_node_num, hidden_node_num, lr, binary_kind=\"withoutzero\", \n",
    "           epochs=30000, batch_size = 5, compute_detail=True)\n",
    "\n",
    "rbm2 = RBM(visible_node_num, hidden_node_num, lr, binary_kind=\"withzero\", \n",
    "           epochs=30000, batch_size = 5, compute_detail=True)\n",
    "rbm2.v_bias = rbm1.v_bias.copy()\n",
    "rbm2.h_bias = rbm1.h_bias.copy()\n",
    "rbm2.W = rbm1.W\n",
    "\n",
    "rbm1.train(train_data1)\n",
    "rbm2.train(train_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22acf413",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/92/zgzs76j97j3f_tf8rngzx_580000gn/T/ipykernel_63228/1487381025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mKL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'KL' is not defined"
     ]
    }
   ],
   "source": [
    "KL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
